
experiment_name:
  Auto_config

pytorch_seed:
  2021
data:
  cifar10
parameters:
  # default parameters
  sigma:
    0.1
  length:
    25
  batch_size:
    64
  epoch:
    100
  droupout:
    0.3
  filter_tau_m:
    4
  filter_tau_s:
    1
  train_coefficients:
    True
  train_bias:
    True
  membrane_filer:
    False
shape:
  - 2
  - 2
  - 2
optimizer:
  optimizer_choice:
    'Adam'
  Adam:
    lr: 0.005
    weight_decay: 0
  AdamW:
    lr: 0.005
  SAM:
    lr: 0.005
    weight_decay: 0
  SGD:
    momentum: 0.9
    lr: 0.0005
    weight_decay: 1e-4
  ASGD:
    lr: 0.0001
    weight_decay: 1e-4
  Rprop:
    lr: 0.0001
    etas: (0.5,1.5)


scheduler:
  scheduler_choice:
    'SchedulerLR'
  SchedulerLR:
    milestones:
      - 0.5
      - 0.75
      - 0.875
      - 0.9375
    gamma:
      0.5
  MultiStepLR:
    milestones:
      - 25
      - 35
    gamma:
      0.1
  CosineAnnealingWarmRestarts:
    T_0:
      1000
  CyclicLR:
    base_lr:
      0.0001
    max_lr:
      0.001
    step_size_up:
      2000

transform:
  RandomResizedCrop:
    size:
      28
    scale:
      - 0.85
      - 1.0
    ratio:
      - 0.75
      - 1.3333333333333333
    interpolation:
      2
  RandomRotation:
    angle:
      15
  RandomApply:
    probability:
      0.5

mnist_config:
  max_rate:
    1
  use_transform:
    True
output:
  ./output