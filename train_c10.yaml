
experiment_name:
  Auto_config
set_seed:
  False
pytorch_seed:
  2021
data:
  cifar10
num_classes:
  10
feature_list:
  - 16
  - 128
  - 256
  - 512
size_list:
  - 32
  - 32
  - 16
  - 8
hidden_size_list:
  - 64
  - 64
  - 64
path_nums_list:
  - 1
  - 1
  - 1
mult_k:
  1
use_standard:
  True
densenetparameter:
  bn_size:
    2
  drop_rate:
    0.1
  use_size_change:
    False
parameters:
  # default parameters
  loss_option:
    smooth_cross
  sigma_list:
    - 0.1
    - 0.01
  s:
    4
  push_num:
    2
  length:
    25
  tmp_feature:
    8
  sigma:
    0.1
  batch_size:
    64
  epoch:
    200
  dropout:
    0.1
  filter_tau_m:
    4
  filter_tau_s:
    1
  train_coefficients:
    True
  train_bias:
    True
  membrane_filer:
    False
shape: [2,2,2]
optimizer:
  optimizer_choice:
    'SGD'
  Adam:
    lr: 0.005
    weight_decay: 0
  AdamW:
    lr: 0.005
    weight_decay: 1e-4
  SAM:
    lr: 0.05
    weight_decay: 4e-5
  SGD:
    momentum: 0.9
    lr: 0.1
    weight_decay: 1e-4
  ASGD:
    lr: 0.0001
    weight_decay: 1e-4
  Rprop:
    lr: 0.0001
    etas: (0.5,1.5)


scheduler:
  scheduler_choice:
    'SchedulerLR'
  SchedulerLR:
    milestones:
      - 0.3
      - 0.6
      - 0.8
    gamma:
      0.2
  MultiStepLR:
    milestones:
      - 25
      - 35
    gamma:
      0.1
  CosineAnnealingWarmRestarts:
    T_0:
      1000
  CyclicLR:
    base_lr:
      0.0001
    max_lr:
      0.001
    step_size_up:
      2000

transform:
  RandomResizedCrop:
    size:
      28
    scale:
      - 0.85
      - 1.0
    ratio:
      - 0.75
      - 1.3333333333333333
    interpolation:
      2
  RandomRotation:
    angle:
      15
  RandomApply:
    probability:
      0.5

mnist_config:
  max_rate:
    1
  use_transform:
    True
output:
  ./output